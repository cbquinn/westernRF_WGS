## build database

Following instructions at https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB with SIFT4G algorithm (https://github.com/rvaser/sift4g).

### Dependencies
1.  [SIFT 4G Algorithm](https://github.com/rvaser/sift4g)
2.  Perl  
    *DBI  
    *[Bioperl](http://www.bioperl.org/) for running DB::Fasta  
    *LWP  
    *Switch.pm (`sudo apt-get install libswitch-perl`)
3.  Python3 (which is invoked with`python`)

```
cd /group/ctbrowngrp2/cbquinn/fox4/5_load/sift/
git clone https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB.git scripts_to_build_SIFT_db

conda create -n sift
conda activate sift

# install sift4g
cd ~/bin
git clone --recursive https://github.com/rvaser/sift4g.git sift4g
cd sift4g/
make
# (to run: 
/group/ctbrowngrp2/cbquinn/fox4/5_load/sift/sift4g/bin/sift4g)
# to run (reinstalled in ~/bin): ./bin/sift4g -h

# check for dependencies (no output means instealled)
perl -e 'use DBI'
perl -e 'use Bio::DB::Fasta'
perl -e 'use Switch'
perl -e 'use LWP'

#conda install -c bioconda perl-dbi
#conda install -c bioconda perl-bioperl
#conda install -c compbiocore perl-switch
#conda install -c bioconda perl-lwp-simple

# problem is that perl doesn't have these in its @INC file. 
# print @INC file
perl -e "print \"@INC\"" | tr " " "\n"

/home/cbquinn/perl5/lib/perl5/x86_64-linux-thread-multi
/home/cbquinn/perl5/lib/perl5
/home/cbquinn/perl5/lib/perl5/x86_64-linux-thread-multi
/home/cbquinn/perl5/lib/perl5
/home/cbquinn/miniconda3/envs/sift/lib/perl5/5.32/site_perl
/home/cbquinn/miniconda3/envs/sift/lib/perl5/site_perl
/home/cbquinn/miniconda3/envs/sift/lib/perl5/5.32/vendor_perl
/home/cbquinn/miniconda3/envs/sift/lib/perl5/vendor_perl
/home/cbquinn/miniconda3/envs/sift/lib/perl5/5.32/core_perl
/home/cbquinn/miniconda3/envs/sift/lib/perl5/core_perl

# find where these are in conda
cd $CONDA_PREFIX
find . -type f -name Switch.pm
# switch is here: ./lib/site_perl/5.26.2/Switch.pm
find . -type f -name *Fasta.pm
# is the copy i installed with cpanm somewhere?
find /home/cbquinn/perl5/lib/perl5 -type f -name Switch.pm
# says its here: /home/cbquinn/perl5/lib/perl5/Switch.pm

# see here if it turns out I need to alter @inc
# https://unix.stackexchange.com/questions/282107/how-to-modify-inc-in-perl

```


To find out perl version do
```
which perl
perl -V 
# Summary of my perl5 (revision 5 version 34 subversion 0) configuration:

# try to use cpanminus to intstall perl modules
conda install -c conda-forge perl-app-cpanminus
# note: this does install another version fo perl:   perl               conda-forge/linux-64::perl-5.32.1-2_h7f98852_perl5
# and now it can't find DBI


cpanm Bio::DB::Fasta

cpanm LWP::Simple
cpanm Switch


env PERL5LIB="" PERL_LOCAL_LIB_ROOT="" PERL_MM_OPT="" PERL_MB_OPT="" $CONDA_PREFIX/bin/cpanm packagename


# so that now I get a different perl version
perl- V
#Summary of my perl5 (revision 5 version 32 subversion 1) configuration:

```

### Test database build

```
# first update config file
cd /group/ctbrowngrp2/cbquinn/fox4/5_load/sift/scripts_to_build_SIFT_db/test_files
nano candidatus_carsonella_ruddii_pv_config.txt

# update _<PARENT_DIR>, <SIFT4G_PATH>, <PROTEIN_DB>_
mkdir -p /group/ctbrowngrp2/cbquinn/fox4/5_load/sift/SIFT_databases//candidatus_carsonella_ruddii_pv

cd /group/ctbrowngrp2/cbquinn/fox4/5_load/sift/scripts_to_build_SIFT_db
perl make-SIFT-db-all.pl -config test_files/candidatus_carsonella_ruddii_pv_config.txt --ensembl_download
```

I get an error that this file doesn't exist. I think i have to manually download it and put it in the sift_databases folder

/group/ctbrowngrp2/cbquinn/fox4/slurmscripts/get_uniref.sh
```sh
#!/bin/bash -l
#SBATCH --job-name=uniref
#SBATCH --time 4-00:00:00
#SBATCH --mem=2GB
#SBATCH -p bmh
#SBATCH -A ctbrowngrp
#SBATCH -o /group/ctbrowngrp2/cbquinn/fox4/slurmlogs/get_uniref.out
#SBATCH -e /group/ctbrowngrp2/cbquinn/fox4/slurmlogs/get_uniref.err

cd /group/ctbrowngrp3/scratch/cbquinn/fox/siftdb

# wget https://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/complete/uniprot_sprot.fasta.gz
#gunzip uniprot_sprot.fasta.gz

wget https://ftp.uniprot.org/pub/databases/uniprot/uniref/uniref90/uniref90.fasta.gz
gunzip uniref90.fasta.gz
```
whoo hooo! that worked
redoing this with uniref90 because I'm running out of things to try. I wonder if it's possible that the uniref didn't finish downloading? 
### partial homo sapiens test
```
cd /group/ctbrowngrp2/cbquinn/fox4/5_load/sift/scripts_to_build_SIFT_db/test_files/

# Set variables in the config file **homo_sapiens-test.txt**: _<SIFT4G_PATH>_ and _<PROTEIN_DB>_

# Note that <PARENT_DIR> is **already** set to ./test_files/homo_sapiens_small  
SIFT scripts will look for the genome and gene annotation files in that folder (which are provided in this example).
```
Now run human test file...

/group/ctbrowngrp2/cbquinn/fox4/slurmscripts/sift_database_test.sh

```sh
#!/bin/bash -l
#SBATCH --job-name=sift_db
#SBATCH --time 24:00:00
#SBATCH --mem=12GB
#SBATCH -p bmm
#SBATCH -A ctbrowngrp
#SBATCH -o /group/ctbrowngrp2/cbquinn/fox4/slurmlogs/sift_db_test.out
#SBATCH -e /group/ctbrowngrp2/cbquinn/fox4/slurmlogs/sift_db_test.err

conda activate sift

cd /group/ctbrowngrp2/cbquinn/fox4/5_load/sift/scripts_to_build_SIFT_db

perl make-SIFT-db-all.pl -config test_files/homo_sapiens-test.txt
```

## Create sift database for arctic fox

```
cd /group/ctbrowngrp2/cbquinn/fox4/5_load/sift/
cp scripts_to_build_SIFT_db/test_files/homo_sapiens-test.txt arcticfox_db_build.config.txt

# make parent directories
# and move appropriate files
cd /group/ctbrowngrp2/cbquinn/fox4/5_load/sift/SIFT_databases

parentdir=Vulpes_lagopus
REF=/group/ctbrowngrp2/cbquinn/fox4/ref/GCF_018345385.1/GCF_018345385.1_ASM1834538v1_genomic.fna
GTF=/group/ctbrowngrp2/cbquinn/fox4/ref/GCF_018345385.1/genomic.gtf
VCF=/group/ctbrowngrp2/cbquinn/fox4/1_vcfs/variant/n34/bcf_variant_filterA_ac1.dp3.mis20_n34_masked.vcf.gz

# move gtf file here
mkdir -p $parentdir/gene-annotation-src
ln -s $GTF $parentdir/gene-annotation-src

# move ref .fa here
mkdir -p $parentdir/chr-src
ln -s $REF $parentdir/chr-src

mkdir -p $parentdir/dbSNP
ln -s $VCF $parentdir/dbSNP

```

GTF: /group/ctbrowngrp2/cbquinn/fox4/5_load/sift/SIFT_databases/Vulpes_lagopus/genomic.gtf

REF: /group/ctbrowngrp2/cbquinn/fox4/5_load/sift/SIFT_databases/Vulpes_lagopus/GCF_018345385.1_ASM1834538v1_genomic.fna

VCF=/group/ctbrowngrp2/cbquinn/fox4/5_load/sift/SIFT_databases/Vulpes_lagopus/bcf_variant_filterA_ac1.dp3.mis20_n34_masked.vcf.gz

`perl make-SIFT-db-all.pl -config <config_file>`

/group/ctbrowngrp2/cbquinn/fox4/slurmscripts/sift_database_arctic.sh
```sh
#!/bin/bash -l
#SBATCH --job-name=sift_db
#SBATCH --time 4-00:00:00
#SBATCH --mem=100GB
#SBATCH -p bmm
#SBATCH -A ctbrowngrp
#SBATCH -o /group/ctbrowngrp2/cbquinn/fox4/slurmlogs/sift_db_arctic.out
#SBATCH -e /group/ctbrowngrp2/cbquinn/fox4/slurmlogs/sift_db_arctic.err


start=`date +%s`

conda activate sift

cd /group/ctbrowngrp2/cbquinn/fox4/5_load/sift/scripts_to_build_SIFT_db/

perl make-SIFT-db-all.pl -config ../arcticfox_db_build.config.txt &> Vulpes.build.log

end=`date +%s`
runtime=$((end-start))
echo "finished splitting:"
echo $runtime

scontrol show job ${SLURM_JOB_ID}
sstat --format 'JobID,MaxRSS,AveCPU' -P ${SLURM_JOB_ID}.batch
```
killed by out of memory handler - gave it more

dies after 20 hours with this error file
```
converting gene format to use-able input
done converting gene format
making single records file
done making single records template
making noncoding records file
done making noncoding records
make the fasta sequences
done making the fasta sequences
start siftsharp, getting the alignments
/group/ctbrowngrp2/cbquinn/fox4/5_load/sift/sift4g/bin/sift4g -d /group/ctbrowngrp2/cbquinn/fox4/5_load/sift/SIFT_databases/uniprot_sprot.fasta -q /group/ctbrowngrp2/cbquinn/fox4/5_load/sift/SIFT_databases/Vulpes_lagopus/all_prot.fasta --subst /group/ctbrowngrp2/cbquinn/fox4/5_load/sift/SIFT_databases/Vulpes_lagopus/subst --out /group/ctbrowngrp2/cbquinn/fox4/5_load/sift/SIFT_databases/Vulpes_lagopus/SIFT_predictions --sub-results

** Checking query data and substitutions files **

** Searching database for candidate sequences **

** Aligning queries with candidate sequences **
processing database part 1 (size ~1.00 GB): 97.50/100.00%

```


see 
* https://github.com/rvaser/sift4g/issues/30#issuecomment-1322825469
* https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/70

troubleshooting steps:
* remove proteins with strings of X
	* longest string was XXX. I removed that protein (>unassigned_transcript_498)
* increase memory to 100GB
* run next script

Ok, it's getting hung up seemingly in the same spot. More looking around on github issues... like this one: https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/10

Based on that, checked the all_prot.fasta for funny things and deleted 9 more transcripts that had an X in them. Then ran again
```
cat /group/ctbrowngrp2/cbquinn/fox4/5_load/sift/SIFT_databases/Vulpes_lagopus/all_prot.fasta | grep -v ">" | grep -n X

# this returns the followign lines with 1 or 2 x
lines 
21171 MECFHTRFSAWTPFSNKSLNRQLFQERVALISHWFDLWTNKQRQEFLFTIFXXCSKSQLRCVQDWFSERMQVAKLDFSTVLPRFISLYIFSFLNPKDLCAAAQVS XM_041732245.1
27819 MNSFVYSQLIYLVSSLLHWLNFKIIVLGFRSQFYTYQQCDCGTRVLIKQERRKQKEYFEKKRLKSKMKLLGVSSPVKNSTVSLDLLNLYMVNHISCQKKTPETVRKPIHVNMYRDI XM_041735580.1
30099 MASVTKVTDKRHNPVESICRKIRAIQKREEISDPVRQILKYQSSNFDSPQINTKKDFEEVLKNMGITPIPLPNTYFSRTEKDYAIVTSPQMMSPRAPSISHLSSPKNATYPVSLTSSENLSRPRSQNSQNLT XM_041736733.1
37465 MARAECSLLTTPGPSPDPGDSEAELDCSFNEEFKFILLPVSYTVVFLLGLGLNTLTLWLFFFRLRPWDATATYMFHLALSDTLYVLSL XM_041740421.1
66691 MRAFSPVRSVRKNSLLDHSLVISRHKTLVEDQMSLLYNMNDGYSRLKELVPSSPQNKKVSKMEILQQGTLGLQ XM_041755080.1
81409 XLQRQLIHHRWGLPQKIQESIQLLLSSTDQSTLSWSSTTLANVHAPQPTALEATGAGDPFSPVTDQVP XM_041762460.1
93631 MALHSEDDSSACQSTMFHSAGDLSSGFLWPPTSSPGTAWVSFSTHLQKSPLHEYHGSLFPKENLEKRVGQWSPSAKADKHGIIYPSTKERMSSKLELTEEQKQETQEAFDLFDADGIGTIDVKELKMAMRAPGLEPQKEEIKKMIREVTWVTQKXXIDREWTGKMNFSDFLTVMTQKISEKDTKEEILKTFKFFN XM_041768584.1
105215 INIFASCMITALILLTLPIIITSTKFYKDKLYPYYVKTATSYAFIISIIPAIIFIYSGQEIVISNAHAITIKTIKLSISFKLDYFSIIFVPVALFVTASIIEFSIAYMHSDPYINRFFKYLLIFLITIMILVTANNIFQLFIGAEGVGIMSFLLIGXXYGRTDANTAALQAILYNRIGDVGFIIAIAAFLLYLNAWDLQQIFISTNDNLNLPLLGLLLAATGKSAQFGLH unassigned_transcript_529
105219 MTNIRKTHPLAKIVNDSFIDLPAPSNISAXXNFGSLLGVCLILQIVTGLFLAIHYTSDTATAFSSVTH unassigned_transcript_532
105191 VNVAALIKQGTENAKMSHETPATQRFGPGLPISPXXTYTCKPPRPSENALKIINDLKEQVSSALLSSSAHLAKPHPHGIQQXXKLSHERKFDAVM unassigned_transcript_498

cat all_prot.fasta | grep -v ">" | grep "-"
cat all_prot.fasta | grep -v ">" | grep "*"

# these are ones i added to check for
cat all_prot.fasta | grep -v ">" | grep "\."
cat all_prot.fasta | grep -v ">" | grep "B"
cat all_prot.fasta | grep -v ">" | grep "Z"
cat all_prot.fasta | grep -v ">" | grep "J"

# these return nothing

# how many proteins?
cat all_prot.fasta | grep ">" | wc -l
# 52627

# any duplicate proteins?
cat all_prot.fasta | grep ">" | sort | uniq -cd
# no..


```
52628 proteins in original file; 52618 in file after deleting ones with Xs

/group/ctbrowngrp2/cbquinn/fox4/slurmscripts/sift_database_arctic2.sh

```sh
#!/bin/bash -l
#SBATCH --job-name=sift_db
#SBATCH --time 3-00:00:00
#SBATCH --mem=250GB
#SBATCH -p bmm
#SBATCH -A ctbrowngrp
#SBATCH -o /group/ctbrowngrp2/cbquinn/fox4/slurmlogs/sift_db_arctic2.out
#SBATCH -e /group/ctbrowngrp2/cbquinn/fox4/slurmlogs/sift_db_arctic2.err

start=`date +%s`

set â€“o errexit 
conda activate sift

cd /group/ctbrowngrp2/cbquinn/fox4/5_load/sift/scripts_to_build_SIFT_db/

/group/ctbrowngrp2/cbquinn/fox4/5_load/sift/sift4g/bin/sift4g -d /group/ctbrowngrp2/cbquinn/fox4/5_load/sift/SIFT_databases/uniprot_sprot.fasta -q /group/ctbrowngrp2/cbquinn/fox4/5_load/sift/SIFT_databases/Vulpes_lagopus/all_prot.fasta --subst /group/ctbrowngrp2/cbquinn/fox4/5_load/sift/SIFT_databases/Vulpes_lagopus/subst --out /group/ctbrowngrp2/cbquinn/fox4/5_load/sift/SIFT_databases/Vulpes_lagopus/SIFT_predictions --sub-results &> Vulpes.build2.log

perl make-SIFT-db-all-downstream-sift4g.pl -conf /group/ctbrowngrp2/cbquinn/fox4/5_load/sift/arcticfox_db_build.config.txt &> Vulpes.build3.log

end=`date +%s`
runtime=$((end-start))
echo "finished splitting:"
echo $runtime

scontrol show job ${SLURM_JOB_ID}
sstat --format 'JobID,MaxRSS,AveCPU' -P ${SLURM_JOB_ID}.batch

```

You're restarting the script? If you do this, you need to delete the folder and start anew. This is because /ine 104 in make-SIFT-db-all.pl appends fasta sequences to the file all_prot.fasta . If you run it more than once, you'll have duplicates and get the out-of-memory error I see above.

Ok... so let's delete the Vulpes folder and rerun from scratch 1x. Then delete the proteins with X and the second part.. 
But I'm not sure that did anything because fasta file is the same size. I also can't find any duplicates

Running again anyway... Next thing to try is removing all the unasigned transcripts.

# Going to try with uniref, and use ctbrowngrp3

```
#!/bin/bash -l
#SBATCH --job-name=uniref
#SBATCH --time 4-00:00:00
#SBATCH --mem=2GB
#SBATCH -p bmh
#SBATCH -A ctbrowngrp
#SBATCH -o /group/ctbrowngrp2/cbquinn/fox4/slurmlogs/get_uniref.out
#SBATCH -e /group/ctbrowngrp2/cbquinn/fox4/slurmlogs/get_uniref.err

cd /group/ctbrowngrp3/scratch/cbquinn/fox/siftdb

# wget https://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/complete/uniprot_sprot.fasta.gz
#gunzip uniprot_sprot.fasta.gz

wget https://ftp.uniprot.org/pub/databases/uniprot/uniref/uniref90/uniref90.fasta.gz
gunzip uniref90.fasta.gz

```

## Create sift database for arctic fox

```

cp /group/ctbrowngrp2/cbquinn/fox4/5_load/sift/arcticfox_db_build.config.txt /group/ctbrowngrp2/cbquinn/fox4/5_load/sift/scripts_to_build_SIFT_db/arcticfox_db2_build.config.txt

# make parent directories
# and move appropriate files
cd /group/ctbrowngrp3/scratch/cbquinn/fox/siftdb

parentdir=Vulpes_lagopus
REF=/group/ctbrowngrp2/cbquinn/fox4/ref/GCF_018345385.1/GCF_018345385.1_ASM1834538v1_genomic.fna
GTF=/group/ctbrowngrp2/cbquinn/fox4/ref/GCF_018345385.1/genomic.gtf
VCF=/group/ctbrowngrp2/cbquinn/fox4/1_vcfs/variant/n34/bcf_variant_filterA_ac1.dp3.mis20_n34_masked.vcf.gz

# move gtf file here
mkdir -p $parentdir/gene-annotation-src
ln -s $GTF $parentdir/gene-annotation-src

# move ref .fa here
mkdir -p $parentdir/chr-src
ln -s $REF $parentdir/chr-src

mkdir -p $parentdir/dbSNP
ln -s $VCF $parentdir/dbSNP

```
nano /group/ctbrowngrp2/cbquinn/fox4/5_load/sift/scripts_to_build_SIFT_db/arcticfox_db2_build.config.txt

/group/ctbrowngrp3/scratch/cbquinn/fox/siftdb/Vulpes_lagopus

Did this:To make sure intermediate files are kept, please comment out line 157 of make-SIFT-db-all.pl

Original:  
`system ("rm $rm_dir");`

New:  
`#system ("rm $rm_dir");`


/group/ctbrowngrp2/cbquinn/fox4/slurmscripts/sift_database_arctic.sh
```sh
#!/bin/bash -l
#SBATCH --job-name=sift_db
#SBATCH --time 4-00:00:00
#SBATCH --mem=100GB
#SBATCH -p bmm
#SBATCH -A ctbrowngrp
#SBATCH -o /group/ctbrowngrp2/cbquinn/fox4/slurmlogs/sift_db_arctic.out
#SBATCH -e /group/ctbrowngrp2/cbquinn/fox4/slurmlogs/sift_db_arctic.err


start=`date +%s`

conda activate sift

cd /group/ctbrowngrp2/cbquinn/fox4/5_load/sift/scripts_to_build_SIFT_db/

perl make-SIFT-db-all.pl -config arcticfox_db2_build.config.txt &> Vulpes.build.log

end=`date +%s`
runtime=$((end-start))
echo "finished splitting:"
echo $runtime

scontrol show job ${SLURM_JOB_ID}
sstat --format 'JobID,MaxRSS,AveCPU' -P ${SLURM_JOB_ID}.batch

```

all prot fast has 157884 lines
52618 prot after (157854)
```
cat /group/ctbrowngrp3/scratch/cbquinn/fox/siftdb/Vulpes_lagopus/all_prot.fasta | grep -v ">" | grep -n X

# 10 proteins to remove with x


MECFHTRFSAWTPFSNKSLNRQLFQERVALISHWFDLWTNKQRQEFLFTIFXXCSKSQLRCVQDWFSE
MNSFVYSQLIYLVSSLLHWLNFKIIVLGFRSQFYTYQQCDCGTRVLIKQERRKQKEYFEKKRLKSKMK
#MASVTKVTDKRHNPVESICRKIRAIQKREEISDPVRQILKYQSSNFDSPQINTKKDFEEVLK
MARAECSLLTTPGPSPDPGDSEAELDCSFNEEFKFILLPVSYTVV
MRAFSPVRSVRKNSLLDHSLVISRHKTLVEDQMSLLYNMNDGYSR
XLQRQLIHHRWGLPQKIQESIQLLLSSTDQSTLSWSSTTLANVHA
MALHSEDDSSACQSTMFHSAGDLSSGFLWPPTSSPGTAWVSFSTH
VNVAALIKQGTENAKMSHETPATQRFGPGLPISPXXTYTCKPPRPSE
INIFASCMITALILLTLPIIITSTKFYKDKLYPYYVKTATSYAFIISIIPAIIF
MTNIRKTHPLAKIVNDSFIDLPAPSNISAXXNFGSLLGVCLILQIVTGLFLAIHYTSDTATAFSSVTHI

cd /group/ctbrowngrp3/scratch/cbquinn/fox/siftdb/Vulpes_lagopus/

# check others
cat all_prot.fasta | grep -v ">" | grep "-"
cat all_prot.fasta | grep -v ">" | grep "*"

# these are ones i added to check for
cat all_prot.fasta | grep -v ">" | grep "\."
cat all_prot.fasta | grep -v ">" | grep "B"
cat all_prot.fasta | grep -v ">" | grep "Z"
cat all_prot.fasta | grep -v ">" | grep "J"
```
/group/ctbrowngrp3/scratch/cbquinn/fox/siftdb/Vulpes_lagopus/all_prot.fasta

/group/ctbrowngrp2/cbquinn/fox4/slurmscripts/sift_database_arctic2.sh

```sh
#!/bin/bash -l
#SBATCH --job-name=sift_db
#SBATCH --time 15-00:00:00
#SBATCH --mem=100GB
#SBATCH --cpus-per-task=8
#SBATCH -p bmm
#SBATCH -A ctbrowngrp
#SBATCH -o /group/ctbrowngrp2/cbquinn/fox4/slurmlogs/sift_db_arctic2.out
#SBATCH -e /group/ctbrowngrp2/cbquinn/fox4/slurmlogs/sift_db_arctic2.err

start=`date +%s`

conda activate sift

cd /group/ctbrowngrp2/cbquinn/fox4/5_load/sift/scripts_to_build_SIFT_db/

/group/ctbrowngrp2/cbquinn/fox4/5_load/sift/sift4g/bin/sift4g -d /group/ctbrowngrp3/scratch/cbquinn/fox/siftdb/uniref90.fasta -q /group/ctbrowngrp3/scratch/cbquinn/fox/siftdb/Vulpes_lagopus/all_prot.fasta --subst /group/ctbrowngrp3/scratch/cbquinn/fox/siftdb/Vulpes_lagopus/subst --out /group/ctbrowngrp3/scratch/cbquinn/fox/siftdb/Vulpes_lagopus/SIFT_predictions --sub-results &> Vulpes.build2.log

perl make-SIFT-db-all-downstream-sift4g.pl -conf arcticfox_db2_build.config.txt &> Vulpes.build3.log

end=`date +%s`
runtime=$((end-start))
echo "all done: $runtime"


scontrol show job ${SLURM_JOB_ID}
sstat --format 'JobID,MaxRSS,AveCPU' -P ${SLURM_JOB_ID}.batch

```

still quits at the same part: processing database part 1 (size ~1.00 GB): 97.50/100.00% *

jarobin reported this here:
https://github.com/rvaser/sift4g/issues/10
followed the directiosn in this post: replaced lines and ran make from sift4g root directory

find ./ -name "cpu_module.c" -type f

./vendor/swsharp/swsharp/src/cpu_module.c
./vendor/swsharp/swsharpwin/swsharp/cpu_module.c

ackk! still didn't work... fails in same spot. going to recompile sift4g from scratch...

```
cd /group/ctbrowngrp2/cbquinn/fox4/5_load/sift
rm -rf sift4g

git clone --recursive https://github.com/rvaser/sift4g.git sift4g
cd sift4g/
# edit
nano -c vendor/swsharp/swsharp/src/cpu_module.c
make
```

test it with the uniprot reference because that's faster
/group/ctbrowngrp2/cbquinn/fox4/slurmscripts/sift_database_arctic2.sh

```sh
#!/bin/bash -l
#SBATCH --job-name=sift_db
#SBATCH --time 15-00:00:00
#SBATCH --mem=100GB
#SBATCH --cpus-per-task=8
#SBATCH -p bmm
#SBATCH -A ctbrowngrp
#SBATCH -o /group/ctbrowngrp2/cbquinn/fox4/slurmlogs/sift_db_arctic2.out
#SBATCH -e /group/ctbrowngrp2/cbquinn/fox4/slurmlogs/sift_db_arctic2.err

start=`date +%s`

conda activate sift

cd /group/ctbrowngrp2/cbquinn/fox4/5_load/sift/scripts_to_build_SIFT_db/

/group/ctbrowngrp2/cbquinn/fox4/5_load/sift/sift4g/bin/sift4g -d /group/ctbrowngrp2/cbquinn/fox4/5_load/sift/SIFT_databases/uniprot_sprot.fasta -q /group/ctbrowngrp3/scratch/cbquinn/fox/siftdb/Vulpes_lagopus/all_prot.fasta --subst /group/ctbrowngrp3/scratch/cbquinn/fox/siftdb/Vulpes_lagopus/subst --out /group/ctbrowngrp3/scratch/cbquinn/fox/siftdb/Vulpes_lagopus/SIFT_predictions --sub-results &> Vulpes.build2.log
squeue -
end=`date +%s`
runtime=$((end-start))
echo "all done: $runtime"

perl make-SIFT-db-all-downstream-sift4g.pl -conf arcticfox_db2_build.config.txt &> Vulpes.build3.log


scontrol show job ${SLURM_JOB_ID}
sstat --format 'JobID,MaxRSS,AveCPU' -P ${SLURM_JOB_ID}.batch

```

the perl script wouldn't run so did
```
cd /group/ctbrowngrp3/scratch/cbquinn/fox/siftdb/Vulpes_lagopus/gene-annotation-src
gzip -c genomic.gtf > genomic.gtf.gz
```
and then reran




less -S /group/ctbrowngrp2/cbquinn/fox4/5_load/sift/scripts_to_build_SIFT_db/Vulpes.build3.log

these are the final genome-wide stats
- Chr
- Genes with SIFT Scores
- Pos with SIFT scores
- Pos with Confident Scores

ALL     99 (52168/52628)        100 (245667718/246644144)       54(132784542/245667718)

### Try out 
```
conda activate sift
```
